{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf36ba4-22d9-4388-a125-26efcd298e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the common size and color mode for all images\n",
    "common_size = (256, 256)\n",
    "common_color_mode = 'RGB'\n",
    "\n",
    "dataset = []\n",
    "\n",
    "main_folder = \"Images\"\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "    folder_path = os.path.join(main_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Resize the image to the common size\n",
    "            image = image.resize(common_size)\n",
    "            \n",
    "            # Convert the image to the common color mode\n",
    "            image = image.convert(common_color_mode)\n",
    "            \n",
    "            label = folder_name\n",
    "            dataset.append((image, label))\n",
    "\n",
    "# Now you have a dataset where each entry is a tuple (image, label).\n",
    "\n",
    "# Convert the dataset to NumPy arrays\n",
    "images = [np.array(entry[0]) for entry in dataset]\n",
    "labels = [entry[1] for entry in dataset]\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1005731-cbf9-4556-ab71-d49af79c68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cf76a4-2ba3-45c6-a1a1-ef943072a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cade989b-3fdd-47ba-b885-471dedb5886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_reshaped = y_train.reshape(-1, 1)\n",
    "y_test_reshaped = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095459fd-861c-4011-baae-3e48d7290d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combat = \"combat\"\n",
    "rehab = \"humanitarianaid\"\n",
    "military_vehicles = \"militaryvehicles\"\n",
    "fire = \"fire\"\n",
    "destroyed_building = \"destroyedbuilding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d16b33-cc79-419d-b310-89c2eab4ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Combat','DestroyedBuildings','Fire','Humanitarian Aid and rehabilitation','Military vehicles and weapons']\n",
    "arr = [combat,rehab,military_vehicles,fire,destroyed_building]\n",
    "for i in range(5):\n",
    "    for j in range(80):\n",
    "        mask = (labels == label[i])\n",
    "        labels[mask] = arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501c2bfe-f01c-4a21-922e-4d31f19af07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combat = \"combat\"\n",
    "rehab = \"humanitarianaid\"\n",
    "military_vehicles = \"militaryvehicles\"\n",
    "fire = \"fire\"\n",
    "destroyed_building = \"destroyedbuilding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f55988-a568-45dd-b008-a6428b1448c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Python lists for y_train and y_test\n",
    "# label_mapping = {\n",
    "#     \"Combat\": combat,\n",
    "#     \"Humanitarian Aid and rehabilitation\": rehab,\n",
    "#     \"Military vehicles and weapons\": military_vehicles,\n",
    "#     \"Fire\": fire,\n",
    "#     \"DestroyedBuildings\": destroyed_building\n",
    "# }\n",
    "label_mapping = {\n",
    "    \"Combat\": 0,\n",
    "    \"Humanitarian Aid and rehabilitation\": 1,\n",
    "    \"Military vehicles and weapons\": 2,\n",
    "    \"Fire\": 3,\n",
    "    \"DestroyedBuildings\": 4\n",
    "}\n",
    "\n",
    "y_train_list = [label[0] for label in y_train_reshaped]\n",
    "y_test_list = [label[0] for label in y_test_reshaped]\n",
    "\n",
    "# Now, create a NumPy array by mapping the labels\n",
    "y_train_int = np.array([label_mapping[label] for label in y_train_list])\n",
    "y_test_int = np.array([label_mapping[label] for label in y_test_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0491978f-9ac6-4b1d-9bb9-3d3773466b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Transform target variable into one-hotencoding\n",
    "y_cat_train = to_categorical(y_train_int, 5)\n",
    "y_cat_test = to_categorical(y_test_int, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52cca168-556c-4a42-98a6-b0342ffbceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8075b8-41fd-4c8d-bc32-bb574e848c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# Pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# Dropout layers\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3, 3), input_shape=(256, 256, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a979ec19-0fa9-4788-b433-1d52260f0623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 256)     7168      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256, 256, 256)     1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 256)     590080    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256, 256, 256)     1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 256)     0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 128, 256)     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 512)     1180160   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128, 128, 512)     2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 512)     2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128, 128, 512)     2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 1024)      4719616   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64, 64, 1024)      4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 1024)      9438208   \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 1024)      4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 1024)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 32, 1024)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1048576)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1073742848\n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1092057349 (69.87 MB)\n",
      "Trainable params: 1092050181 (69.84 MB)\n",
      "Non-trainable params: 7168 (28.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rites\\miniconda3\\envs\\GG_3831\\lib\\site-packages\\keras\\src\\utils\\layer_utils.py:146: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  total_memory_size += weight_shape * per_param_size\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81453fe8-0428-438d-bfbb-6b0e4410da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f72f60bc-d816-4370-95f1-4b4792913ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_generator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "train_generator = data_generator.flow(X_train, y_cat_train, batch_size)\n",
    "steps_per_epoch = X_train.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd733b8c-3d54-4f3d-88f7-90a5f93fb253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b2f44-00a8-4aee-8323-12d29419cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
